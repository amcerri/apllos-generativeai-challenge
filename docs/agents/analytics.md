# Analytics Agent

Covers the planner, executor, and normalizer modules.

## Planner ([app/agents/analytics/planner.py](../../app/agents/analytics/planner.py))

- Purpose: Translate NL requests into safe SQL bounded by an allowlist.
- Features:
  - Prompt engineering with Chain-of-Thought reasoning.
  - Heuristics for preview/aggregate/time series queries.
  - Allowlist validation of identifiers; join validation; schema prefix fixing; alias dot fixes.
  - OpenAI tool calling backend (preferred) with JSON Schema fallback using `llm_client` and prompts.
  - Tool calling reduces token usage compared to JSON Schema mode.
  - Config-driven limits: `default_limit`, `max_limit`, examples count.
- Output: `PlannerPlan` with `sql`, `params`, `reason`, `limit_applied`, `warnings`.

## Executor ([app/agents/analytics/executor.py](../../app/agents/analytics/executor.py))

- Purpose: Execute planner SQL safely.
- Safety:
  - Read-only transaction; `statement_timeout` per query (increased to 120s).
  - Client row caps; GROUP BY heuristic raises cap to avoid truncating categorical sets.
  - Window functions support (LAG, LEAD, ROW_NUMBER, RANK, OVER, PARTITION BY, ORDER BY).
  - EXPLAIN (FORMAT JSON) attached when requested; optional ANALYZE via env.
  - Circuit breaker keyed by SQL hash with backoff after repeated failures.
- Output: `ExecutorResult` with `rows`, counts, latency, warnings, and `meta` (sql, row_cap, timeout, explain, breaker stats).

## Normalizer ([app/agents/analytics/normalize.py](../../app/agents/analytics/normalize.py))

- Purpose: Convert raw rows into PT-BR business narrative with expert-like interpretative analysis.
- Expert-Like Multi-Stage Analysis:
  - **Stage 1 (Descriptive)**: Executive summary of key numbers, distributions, averages, and totals.
  - **Stage 2 (Interpretative)**: Pattern identification (trends, seasonality, concentrations), comparisons, anomalies, and business context.
  - **Stage 3 (Actionable)**: Opportunities, risks, alerts, and recommended next steps.
  - Analysis depth adapts to query complexity (simple counts → Stage 1 only; complex analysis → all 3 stages).
- Intelligent Data Display Decision:
  - Semantic query analysis using `SemanticQueryAnalyzer` to determine optimal display strategy.
  - Query type detection (distribution, top-N, temporal, correlation, aggregation, count).
  - Intent analysis (explicit_all, implicit_all, analysis, summary).
  - Adaptive display rules: shows all 27 states when requested, but intelligently summarizes 1000+ records.
  - Rules by query type: distributions (≤50 items show all), top-N (always show all), temporal (≤24 periods show all).
- LLM-First Approach:
  - System prompt with multi-stage analysis guidelines and pattern detection priorities.
  - Human-like responses with analytical context instead of raw SQL-like outputs.
  - Configurable threshold (`complete_data_threshold`, default 100 records) for automatic data balancing.
- Paths:
  - LLM-based: system prompt + examples; produces JSON (`text`, optional structured payload).
  - Fallback: deterministic formatting with insights for small/medium/large datasets.
- Caching:
  - Response cache for similar queries with same SQL and result context.
  - Cache key includes user query, agent name, SQL plan, and result metadata.
  - Reduces redundant LLM calls for repeated or similar analytics queries.
- Advanced Pattern Detection:
  - **Statistical patterns**: Variance analysis, coefficient of variation, distribution shape.
  - **Business patterns**: Geographic concentration, category dominance, temporal trends.
  - **Anomaly detection**: IQR-based outlier identification with automatic flagging.
  - **Pattern types**: 1:1 ratios, dominance, geographic/category concentration, temporal trends, anomalies, statistical variability.
- Extras:
  - For large outputs, sampling for LLM then full data appended in response.
  - Dynamic "no results" messages generated by LLM instead of hardcoded responses.

---

**← [Back to Documentation Index](../README.md)**
